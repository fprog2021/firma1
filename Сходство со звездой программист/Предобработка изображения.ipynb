{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d12aa90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "print(os.getcwd())\n",
    "os.chdir('C://Users//IQ//Pictures//Camera Roll')\n",
    "image = cv2.imread('WIN_20210728_12_28_15_Pro.jpg')\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79dbbe90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def viewImage(name_of_window, image):\n",
    "#     cv2.namedWindow(name_of_window, cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow(name_of_window, image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae6ad96c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Преобразование в чб градации\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "viewImage(\"Gray.jpg\", gray_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f2643a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640)\n",
      "(480, 640, 3) (200, 266)\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('2.jpg')\n",
    "scale_percent = 200 / min(gray_image.shape[1], gray_image.shape[0])\n",
    "width = int(gray_image.shape[1] * scale_percent)\n",
    "height = int(gray_image.shape[0] * scale_percent)\n",
    "dim = (width, height)\n",
    "print(gray_image.shape)\n",
    "# Изменение размера фотографии\n",
    "resized = cv2.resize(gray_image, dim, interpolation = cv2.INTER_AREA)\n",
    "viewImage(\"Resize.jpg\", resized)\n",
    "print(image.shape, resized.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab3ebe5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240, 240, 3)\n"
     ]
    }
   ],
   "source": [
    "# Кадрирование\n",
    "size = min(image.shape[0], image.shape[1])\n",
    "cropped = image[image.shape[0]-size//2:image.shape[0]-size//2+size, image.shape[1]-size//2:image.shape[1]-size//2+size]\n",
    "viewImage(\"Cropped image.jpg\", cropped)\n",
    "print(cropped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bf80866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Черно - белый\n",
    "ret, threshold_image = cv2.threshold(gray_image, 130, 255, 0) # ret - ?\n",
    "viewImage(\"blackWhite image.jpg\", threshold_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "498a3738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выделение контуров\n",
    "_, contours, hierarchy = cv2.findContours(threshold_image, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "blank_image = np.zeros((image.shape[0], image.shape[1], 3), np.uint8)\n",
    "blank_image[:,:] = (255, 255, 255)\n",
    "cont = cv2.drawContours(blank_image, contours, -1, (255, 0, 0), 3)\n",
    "viewImage(\"Contours image.jpg\", cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa10bbc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(304, 180) (489, 366)]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import dlib\n",
    "face_detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"C://Users//IQ//Downloads//shape_predictor_68_face_landmarks.dat//shape_predictor_68_face_landmarks.dat\")\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "face_rect = detector(image, 1)[0]\n",
    "print(face_rect)\n",
    "output = image.copy()\n",
    "win = dlib.image_window()\n",
    "win.clear_overlay()\n",
    "win.set_image(gray_image)\n",
    "win.add_overlay(face_rect)\n",
    "dlib.hit_enter_to_continue()\n",
    "# cv2.rectangle(output, a, b, (0, 255, 255), 40)\n",
    "# viewImage(\"Face.jpg\", output)\n",
    "# points = predictor(image, face_rect)\n",
    "# landmarks = np.array([*map(lambda p: [p.x, p.y], points.parts())])\n",
    "# print(len(landmarks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0580ee40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
